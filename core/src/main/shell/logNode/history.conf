# =================================
# ====== agent of node begin ======
# =================================
node.sources = iuniSrc
node.sinks = hdfsSink1 hdfsSink2 hdfsSink3 hbaseSink1 hbaseSink2 hbaseSink3
node.channels = hdfsChannel hbaseChannel
node.sinkgroups = hdfsSinkGroup hbaseSinkGroup

# node hdfsChannel
node.channels.hdfsChannel.type = SPILLABLEMEMORY
node.channels.hdfsChannel.memoryCapacity = 1000000
node.channels.hdfsChannel.transactionCapacity = 10000
node.channels.hdfsChannel.overflowCapacity = 100000000
node.channels.hdfsChannel.avgEventSize = 3000
node.channels.hdfsChannel.keep-alive = 10
node.channels.hdfsChannel.write-timeout = 10
node.channels.hdfsChannel.checkpointDir = /data/flume-ng/checkpoint/hdfs
node.channels.hdfsChannel.dataDirs = /data/flume-ng/data/hdfs

# node hbaseChannel
node.channels.hbaseChannel.type = SPILLABLEMEMORY
node.channels.hbaseChannel.memoryCapacity = 1000000
node.channels.hbaseChannel.transactionCapacity = 10000
node.channels.hbaseChannel.overflowCapacity = 100000000
node.channels.hbaseChannel.avgEventSize = 3000
node.channels.hbaseChannel.keep-alive = 10
node.channels.hbaseChannel.write-timeout = 10
node.channels.hbaseChannel.checkpointDir = /data/flume-ng/checkpoint/hbase
node.channels.hbaseChannel.dataDirs = /data/flume-ng/data/hbase

# node hdfsSrc
node.sources.iuniSrc.type = exec
node.sources.iuniSrc.command = tail -fn0 /usr/local/nginx-1.4.4/logs/www.iuni.com_access.log
node.sources.iuniSrc.interceptors = inte
node.sources.iuniSrc.interceptors.inte.type = com.iuni.data.analyze.flume.IuniLogInterceptor$Builder
node.sources.iuniSrc.interceptors.inte.startDate = 20141118103200
node.sources.iuniSrc.interceptors.inte.adId = AD_ID
node.sources.iuniSrc.interceptors.inte.useIP = false
node.sources.iuniSrc.interceptors.inte.hostHeader = hostname
node.sources.iuniSrc.interceptors.inte.ipIndex = 4
node.sources.iuniSrc.interceptors.inte.urlIndex = 7
node.sources.iuniSrc.interceptors.inte.statusIndex = 8
node.sources.iuniSrc.interceptors.inte.statusError = false
node.sources.iuniSrc.interceptors.inte.requestTimeIndex = 3
node.sources.iuniSrc.interceptors.inte.static = false
node.sources.iuniSrc.interceptors.inte.staticRes = css js jpg jpeg png gif ico img bmp min small
node.sources.iuniSrc.interceptors.inte.staticRes.jpg.specialUrl = specialUrl
node.sources.iuniSrc.interceptors.inte.staticRes.jpeg.specialUrl = specialUrl
node.sources.iuniSrc.interceptors.inte.staticRes.png.specialUrl = specialUrl
node.sources.iuniSrc.interceptors.inte.staticRes.gif.specialUrl = specialUrl
node.sources.iuniSrc.interceptors.inte.staticRes.ico.specialUrl = specialUrl
node.sources.iuniSrc.interceptors.inte.staticRes.img.specialUrl = specialUrl
node.sources.iuniSrc.interceptors.inte.staticRes.bmp.specialUrl = specialUrl
# node iuniSrc channels
node.sources.iuniSrc.channels = hdfsChannel hbaseChannel

# node hdfsSink1
node.sinks.hdfsSink1.type=avro
node.sinks.hdfsSink1.hostname = 18.8.0.245
node.sinks.hdfsSink1.port = 4141
node.sinks.hdfsSink1.batch-size = 1000
node.sinks.hdfsSink1.channel = hdfsChannel
# node hdfsSink1 channel
# node hdfsSink2
node.sinks.hdfsSink2.type=avro
node.sinks.hdfsSink2.hostname = 18.8.5.130
node.sinks.hdfsSink2.port = 4141
node.sinks.hdfsSink2.batch-size = 1000
# node hdfsSink2 channel
node.sinks.hdfsSink2.channel = hdfsChannel
# node hdfsSink3
node.sinks.hdfsSink3.type=avro
node.sinks.hdfsSink3.hostname = 18.8.5.131
node.sinks.hdfsSink3.port = 4141
node.sinks.hdfsSink3.batch-size = 1000
# node hdfsSink3 channel
node.sinks.hdfsSink3.channel = hdfsChannel

# node hdfs sink group
node.sinkgroups.hdfsSinkGroup.sinks = hdfsSink1 hdfsSink2 hdfsSink3
node.sinkgroups.hdfsSinkGroup.processor.type = load_balance
node.sinkgroups.hdfsSinkGroup.processor.selector = round_robin
node.sinkgroups.hdfsSinkGroup.processor.backoff = true

# node hbaseSink1
node.sinks.hbaseSink1.type=avro
node.sinks.hbaseSink1.hostname = 18.8.0.245
node.sinks.hbaseSink1.port = 4142
node.sinks.hbaseSink1.batch-size = 1000
# node hbaseSink1 channel
node.sinks.hbaseSink1.channel = hbaseChannel
# node hbaseSink2
node.sinks.hbaseSink2.type=avro
node.sinks.hbaseSink2.hostname = 18.8.5.130
node.sinks.hbaseSink2.port = 4142
node.sinks.hbaseSink2.batch-size = 1000
# node hbaseSink2 channel
node.sinks.hbaseSink2.channel = hbaseChannel
# node hbaseSink3
node.sinks.hbaseSink3.type=avro
node.sinks.hbaseSink3.hostname = 18.8.5.131
node.sinks.hbaseSink3.port = 4142
node.sinks.hbaseSink3.batch-size = 1000
# node hbaseSink3 channel
node.sinks.hbaseSink3.channel = hbaseChannel

# node hbase sink group
node.sinkgroups.hbaseSinkGroup.sinks = hbaseSink1 hbaseSink2 hbaseSink3
node.sinkgroups.hbaseSinkGroup.processor.type = load_balance
node.sinkgroups.hbaseSinkGroup.processor.selector = round_robin
node.sinkgroups.hbaseSinkGroup.processor.backoff = true

# ===============================
# ====== agent of node end ======
# ===============================





# ======================================
# ====== agent of collector begin ======
# ======================================
collector.sources = hdfsSource hbaseSource
collector.sinks = hdfsSink hbaseSink
collector.channels = hdfsChannel hbaseChannel

# collector hdfsChannel
collector.channels.hdfsChannel.type = SPILLABLEMEMORY
collector.channels.hdfsChannel.memoryCapacity = 1000000
collector.channels.hdfsChannel.transactionCapacity = 10000
collector.channels.hdfsChannel.overflowCapacity = 100000000
collector.channels.hdfsChannel.avgEventSize = 3000
collector.channels.hdfsChannel.keep-alive = 10
collector.channels.hdfsChannel.write-timeout = 10
collector.channels.hdfsChannel.checkpointDir = /home/data/flume-ng/checkpoint/hdfs
collector.channels.hdfsChannel.dataDirs = /home/data/flume-ng/data/hdfs
# collector hbaseChannel
collector.channels.hbaseChannel.type = SPILLABLEMEMORY
collector.channels.hbaseChannel.memoryCapacity = 1000000
collector.channels.hbaseChannel.transactionCapacity = 10000
collector.channels.hbaseChannel.overflowCapacity = 100000000
collector.channels.hbaseChannel.avgEventSize = 3000
collector.channels.hbaseChannel.keep-alive = 10
collector.channels.hbaseChannel.write-timeout = 10
collector.channels.hbaseChannel.checkpointDir = /home/data/flume-ng/checkpoint/hbase
collector.channels.hbaseChannel.dataDirs = /home/data/flume-ng/data/hbase

# collector hdfsSource
collector.sources.hdfsSource.type = avro
collector.sources.hdfsSource.bind = 0.0.0.0
collector.sources.hdfsSource.port = 4141
# collector hdfsSource channels
collector.sources.hdfsSource.channels = hdfsChannel

# collector hbaseSource
collector.sources.hbaseSource.type = avro
collector.sources.hbaseSource.bind = 0.0.0.0
collector.sources.hbaseSource.port = 4142
# collector hbaseSource channels
collector.sources.hbaseSource.channels = hbaseChannel

# collector hbaseSink
collector.sinks.hdfsSink.type = hdfs
collector.sinks.hdfsSink.hdfs.path = hdfs://testCluster/flume/logs/use=%{suffixUsable}/year=%Y/month=%m/day=%d/hour=%H/minute=%M/time=%Y%m%d%H%M
collector.sinks.hdfsSink.hdfs.fileType = DataStream
collector.sinks.hdfsSink.hdfs.filePrefix = iuni
collector.sinks.hdfsSink.hdfs.fileSuffix = .log
collector.sinks.hdfsSink.hdfs.batchSize = 10000
collector.sinks.hdfsSink.hdfs.rollInterval = 30
collector.sinks.hdfsSink.hdfs.rollSize = 0
collector.sinks.hdfsSink.hdfs.rollCount = 10000
collector.sinks.hdfsSink.serializer = com.iuni.data.analyze.flume.IuniLogTextSerializer$Builder
# collector hdfsSink channel
collector.sinks.hdfsSink.channel = hdfsChannel

# collector hbaseSink
collector.sinks.hbaseSink.type = hbase
collector.sinks.hbaseSink.table = iunilog
collector.sinks.hbaseSink.columnFamily = f
collector.sinks.hbaseSink.batchSize = 10000
collector.sinks.hbaseSink.serializer = com.iuni.data.analyze.flume.IuniLogHbaseSerializer
# collector hbaseSink channel
collector.sinks.hbaseSink.channel = hbaseChannel

# ====================================
# ====== agent of collector end ======
# ====================================




# ====================================
# ====== agent of history begin ======
# ====================================
history.sources = historySrc
history.sinks = hdfsSink hbaseSink
history.channels = hdfsChannel hbaseChannel

# history hdfsChannel
history.channels.hdfsChannel.type = SPILLABLEMEMORY
history.channels.hdfsChannel.memoryCapacity = 1000000
history.channels.hdfsChannel.transactionCapacity = 10000
history.channels.hdfsChannel.overflowCapacity = 100000000
history.channels.hdfsChannel.avgEventSize = 3000
history.channels.hdfsChannel.keep-alive = 10
history.channels.hdfsChannel.write-timeout = 10
history.channels.hdfsChannel.checkpointDir = /home/data/flume-ng/checkpoint/hdfs
history.channels.hdfsChannel.dataDirs = /home/data/flume-ng/data/hdfs

# history hbaseChannel
history.channels.hbaseChannel.type = SPILLABLEMEMORY
history.channels.hbaseChannel.memoryCapacity = 1000000
history.channels.hbaseChannel.transactionCapacity = 10000
history.channels.hbaseChannel.overflowCapacity = 100000000
history.channels.hbaseChannel.avgEventSize = 3000
history.channels.hbaseChannel.keep-alive = 10
history.channels.hbaseChannel.write-timeout = 10
history.channels.hbaseChannel.checkpointDir = /home/data/flume-ng/checkpoint/hbase
history.channels.hbaseChannel.dataDirs = /home/data/flume-ng/data/hbase

# history historySrc
history.sources.historySrc.type = avro
history.sources.historySrc.bind = 0.0.0.0
history.sources.historySrc.port = 14141
history.sources.historySrc.interceptors = inte
history.sources.historySrc.interceptors.inte.type = com.iuni.data.analyze.flume.IuniLogInterceptor$Builder
history.sources.historySrc.interceptors.inte.adId = AD_ID
history.sources.historySrc.interceptors.inte.useIP = false
history.sources.historySrc.interceptors.inte.hostHeader = hostname
history.sources.historySrc.interceptors.inte.ipIndex = 4
history.sources.historySrc.interceptors.inte.urlIndex = 7
history.sources.historySrc.interceptors.inte.statusIndex = 8
history.sources.historySrc.interceptors.inte.statusError = false
history.sources.historySrc.interceptors.inte.requestTimeIndex = 3
history.sources.historySrc.interceptors.inte.static = false
history.sources.historySrc.interceptors.inte.staticRes = css js jpg jpeg png gif ico img bmp min small
history.sources.historySrc.interceptors.inte.staticRes.jpg.specialUrl = specialUrl
history.sources.historySrc.interceptors.inte.staticRes.jpeg.specialUrl = specialUrl
history.sources.historySrc.interceptors.inte.staticRes.png.specialUrl = specialUrl
history.sources.historySrc.interceptors.inte.staticRes.gif.specialUrl = specialUrl
history.sources.historySrc.interceptors.inte.staticRes.ico.specialUrl = specialUrl
history.sources.historySrc.interceptors.inte.staticRes.img.specialUrl = specialUrl
history.sources.historySrc.interceptors.inte.staticRes.bmp.specialUrl = specialUrl
# node iuniSrc channels
history.sources.historySrc.channels = hdfsChannel hbaseChannel

# history hdfsSink
history.sinks.hdfsSink.type = hdfs
history.sinks.hdfsSink.hdfs.path = hdfs://testCluster/flume/logs/use=%{suffixUsable}/year=%Y/month=%m/day=%d/hour=%H/minute=%M/time=%Y%m%d%H%M
history.sinks.hdfsSink.hdfs.fileType = DataStream
history.sinks.hdfsSink.hdfs.filePrefix = iuni
history.sinks.hdfsSink.hdfs.fileSuffix = .log
history.sinks.hdfsSink.hdfs.batchSize = 10000
history.sinks.hdfsSink.hdfs.rollInterval = 30
history.sinks.hdfsSink.hdfs.rollSize = 0
history.sinks.hdfsSink.hdfs.rollCount = 10000
history.sinks.hdfsSink.serializer = com.iuni.data.analyze.flume.IuniLogTextSerializer$Builder
# history hdfsSink channel
history.sinks.hdfsSink.channel = hdfsChannel

# history hbaseSink
history.sinks.hbaseSink.type = hbase
history.sinks.hbaseSink.table = iunilog
history.sinks.hbaseSink.columnFamily = f
history.sinks.hbaseSink.batchSize = 10000
history.sinks.hbaseSink.serializer = com.iuni.data.analyze.flume.IuniLogHbaseSerializer
# history hbaseSink channel
history.sinks.hbaseSink.channel = hbaseChannel

# ==================================
# ====== agent of history end ======
# ==================================




